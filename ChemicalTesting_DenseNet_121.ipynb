{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import copy \n",
    "import os\n",
    "import openpyxl\n",
    "from openpyxl import Workbook\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from PIL import Image   #  pip install pillow\n",
    "import glob\n",
    "import torch\n",
    "from torch.utils import data\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('PyTorch version:', torch.__version__) \n",
    "print('Python version:',sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_path = glob.glob(r'Data/*/*.tif')\n",
    "imgs_path[-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_path[-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_p = imgs_path[7]\n",
    "img_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_p.split('\\\\')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = [img_p.split('\\\\')[1] for img_p in imgs_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_label = np.unique(label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_index = dict((v, k) for k, v in enumerate(unique_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_label = dict((v, k) for k, v in label_to_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = [label_to_index.get(la) for la in label_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels[-5: ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(imgs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2023)\n",
    "random_index = np.random.permutation(len(imgs_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_path = np.array(imgs_path)[random_index]\n",
    "all_labels = np.array(all_labels)[random_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_path[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_path[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = int(len(imgs_path)*0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = imgs_path[ :i]\n",
    "train_labels = all_labels[ :i]\n",
    "test_path = imgs_path[i: ]\n",
    "test_labels = all_labels[i: ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据集创建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transform = transforms.Compose([\n",
    "                    transforms.Resize((1024, 1024)),\n",
    "                    transforms.ToTensor()                    \n",
    "])\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "                    transforms.Resize((1024, 1024)),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(mean=[0.5,0.5,0.5],std=[0.5,0.5,0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#创建Dataset的子类\n",
    "class Mydataset(data.Dataset):       \n",
    "    def __init__(self, img_paths, labels,transform):  #初始化 图片的路径\n",
    "        self.imgs = img_paths\n",
    "        self.labels = labels\n",
    "        self.transforms = transform\n",
    "\n",
    "    def __getitem__(self, index):   #实现数据切片\n",
    "        img = self.imgs[index]\n",
    "        label = self.labels[index]\n",
    "\n",
    "        pil_img = Image.open(img)       \n",
    "        data = self.transforms(pil_img)\n",
    "\n",
    "        return data, label\n",
    "\n",
    "    def __len__(self):            #返回数据总长度\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = Mydataset(train_path, train_labels, train_transform)\n",
    "test_ds = Mydataset(test_path, test_labels, test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE =10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = data.DataLoader(\n",
    "                           train_ds,\n",
    "                           batch_size=BATCH_SIZE,\n",
    "                           shuffle=True\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dl = data.DataLoader(\n",
    "                          test_ds,\n",
    "                          batch_size=BATCH_SIZE\n",
    "                          )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_batch, labels_batch = next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 12))\n",
    "\n",
    "for i, (img, label) in enumerate(zip(imgs_batch[-6:], labels_batch[-6:])):\n",
    "    #img = img.permute(1, 2, 0).numpy()\n",
    "    img = (img.permute(1, 2, 0).numpy()+1)/2    \n",
    "    plt.subplot(2, 3, i+1)\n",
    "    plt.title(index_to_label.get(label.item()))\n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im=imgs_batch[0].permute(1,2,0)\n",
    "im.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#im=im.numpy()\n",
    "img = (im+1)/2   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构建模型——利用CNN提取特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#densenet121\n",
    "model = torchvision.models.densenet121(pretrained=True)\n",
    "\n",
    "# 冻结DenseNet-121的参数\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "inf = model.classifier.in_features\n",
    "inf\n",
    "num_classes=2\n",
    "# 修改分类层\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Linear(1024, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(512, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(64, num_classes)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型计算量和参数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#方法一：\n",
    "from torchsummary import summary\n",
    "\n",
    "#print(summary(model, input_size=(3, 1024, 1024)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#方法二：\n",
    "total = sum([param.nelement() for param in model.parameters()]) \n",
    "print(\"Number of parameter: %.2fM\" % (total/1e6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#方法三\n",
    "from thop import profile\n",
    "\n",
    "input = torch.randn(1, 3,1024,1024)\n",
    "flops, params = profile(model, inputs=(input,))\n",
    "print('flops: ', flops, 'params: ', params)\n",
    "print('计算量 flops: %.2f M, 模型的参数总量 params: %.2f M' % (flops //1e6, params //1e6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#model(imgs_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#训练函数\n",
    "def train_model(model, train_dataloader, criterion, optimizer, device):\n",
    "\n",
    "    correct=0\n",
    "    total=0\n",
    "    running_loss = 0.0\n",
    "\n",
    "    start_time = time.time()    \n",
    "\n",
    "    model.train()\n",
    "    for inputs, labels in train_dataloader:\n",
    "        labels=torch.tensor(labels,dtype=torch.long)\n",
    "        inputs, labels = inputs.to(device), labels.to(device)        \n",
    "\n",
    "        predict = model(inputs)\n",
    "        loss = criterion(predict,labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        with torch.no_grad():\n",
    "            predict=torch.argmax(predict,dim=1)\n",
    "            correct+=(predict==labels).sum().item()\n",
    "            total+=labels.size(0)\n",
    "            running_loss+=loss.item()\n",
    "\n",
    "    loss = running_loss / len(train_dataloader.dataset)\n",
    "    acc = correct / total\n",
    "\n",
    "    train_time = time.time() - start_time \n",
    "\n",
    "    return loss,acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 评估模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#评估函数\n",
    "def evaluate_model(model, eval_dataloader,criterion, device):\n",
    "\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    test_running_loss = 0.0\n",
    "\n",
    "    predictions = []\n",
    "    targets = []\n",
    "\n",
    "    start_time = time.time()    \n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in eval_dataloader:\n",
    "            labels=torch.tensor(labels,dtype=torch.long)\n",
    "            inputs = inputs.to(device)\n",
    "\n",
    "            predict = model(inputs)\n",
    "            loss = criterion(predict, labels)\n",
    "\n",
    "            predict=torch.argmax(predict,dim=1)\n",
    "\n",
    "            test_correct+=(predict==labels).sum().item()\n",
    "            test_total+=labels.size(0)\n",
    "            test_running_loss+=loss.item()\n",
    "\n",
    "            predictions.extend(predict.cpu().numpy())\n",
    "            targets.extend(labels.numpy())\n",
    "\n",
    "    loss = test_running_loss / len(eval_dataloader.dataset)\n",
    "    acc = test_correct / test_total\n",
    "\n",
    "    eval_time = time.time() - start_time \n",
    "\n",
    "    return loss, acc, predictions, targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 开始训练和评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#重复训练轮次\n",
    "epochs = 20\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 定义损失函数和优化器  \n",
    "criterion = torch.nn.CrossEntropyLoss()   #criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "#模型数据记录\n",
    "best_model_wts = copy.deepcopy(model.state_dict())\n",
    "best_acc = 0.0\n",
    "\n",
    "#训练数据记录\n",
    "train_loss = []\n",
    "train_acc = []\n",
    "eval_loss = []\n",
    "eval_acc = []\n",
    "\n",
    "#评估数据记录\n",
    "eval_preds = []\n",
    "eval_labels = []  \n",
    "\n",
    "# 训练和评估\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_train_loss,epoch_train_acc = train_model(model, train_dl, criterion, optimizer, device)           \n",
    "\n",
    "    # 测试和评估\n",
    "    epoch_eval_loss,epoch_eval_acc,eval_predictions, eval_targets = evaluate_model(model, test_dl,criterion, device)\n",
    "\n",
    "    #性能输出\n",
    "    print(f\"Epoch {epoch+1}/{epochs}: Train Loss: {epoch_train_loss:.4f}   Train Acc: {epoch_train_acc:.4f}  Eval_Loss： {epoch_eval_loss:.4f}   Eval_Acc:{epoch_eval_acc:.4f}\")\n",
    "\n",
    "    if epoch_eval_acc>best_acc:\n",
    "        best_acc=epoch_eval_acc\n",
    "        best_model_wts=copy.deepcopy(model.state_dict())\n",
    "\n",
    "    train_loss.append(epoch_train_loss)\n",
    "    train_acc.append(epoch_train_acc)\n",
    "    eval_loss.append(epoch_eval_loss)\n",
    "    eval_acc.append(epoch_eval_acc)        \n",
    "\n",
    "\n",
    "model.load_state_dict(best_model_wts) \n",
    "\n",
    "print(f\"Model_best_acc: {best_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型参数保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#保存模型权重到文件\n",
    "PATH='DenseNet_Weights.pth'\n",
    "torch.save(model.state_dict(),PATH)\n",
    "print(\"Model weights saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型性能绘图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#损失绘图\n",
    "plt.plot(range(1, epochs+1), train_loss, label='train_loss')\n",
    "plt.plot(range(1, epochs+1), eval_loss, label='eval_loss')\n",
    "plt.legend()\n",
    "\n",
    "# 保存图形\n",
    "save_dir='数据报告'\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.mkdir(save_dir)\n",
    "\n",
    "plt.savefig(save_dir+'DenseNet_loss.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#准确率绘图\n",
    "plt.plot(range(1, epochs+1), train_acc, label='train_acc')\n",
    "plt.plot(range(1, epochs+1), eval_acc, label='eval_acc')\n",
    "plt.legend()\n",
    "\n",
    "# 保存图形\n",
    "save_dir='数据报告'\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.mkdir(save_dir)\n",
    "\n",
    "plt.savefig(save_dir+'DenseNet_Acc.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#损失、准确率数据保存\n",
    "save_dir='数据报告'\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.mkdir(save_dir)\n",
    "\n",
    "book = openpyxl.Workbook()\n",
    "sheet = book.active\n",
    "sheet.title = \"数据报告\"\n",
    "\n",
    "sheet.append(['epochs', 'train_loss','test_loss','train_acc','test_acc'])\n",
    "\n",
    "for i in range(0, epochs):\n",
    "    sheet.append([i+1, train_loss[i], eval_loss[i],train_acc[i],eval_acc[i]])\n",
    "\n",
    "book.save(save_dir+\"/DenseNet_Loss_Accuracy.xlsx\")\n",
    "\n",
    "\n",
    "#range(0,epochs).to_excel(save_dir+\"/ResNet_Loss_Accuracy.xlsx\", encoding=\"utf_8_sig\")\n",
    "#train_loss.to_excel(save_dir+\"/ResNet_Loss_Accuracy.xlsx\", encoding=\"utf_8_sig\")\n",
    "#test_loss.to_excel(save_dir+\"/ResNet_Loss_Accuracy.xlsx\", encoding=\"utf_8_sig\")\n",
    "#test_loss.to_excel(save_dir+\"/ResNet_Loss_Accuracy.xlsx\", encoding=\"utf_8_sig\")\n",
    "#test_acc.to_excel(save_dir+\"/ResNet_Loss_Accuracy.xlsx\", encoding=\"utf_8_sig\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型参数导入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实例化模型\n",
    "#model=Net()\n",
    "# 加载模型权重\n",
    "#model.load_state_dict(torch.load(PATH))\n",
    "print(\"Model weights loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 验证模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 验证模型函数\n",
    "def validate_model(model, val_loader):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, dim=1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    print(f'Validation Accuracy: {100 * correct / total:.2f}%')\n",
    "\n",
    "    return  all_labels,all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels,preds=validate_model(model, test_dl)\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 计算混淆矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#生成混淆矩阵\n",
    "cm = confusion_matrix(labels, preds)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 绘制混淆矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算混淆矩阵\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# confusion_matrix 需要的参数：y_true(真实标签),y_pred(预测标签),normalize(归一化,'true', 'pred', 'all')\n",
    "# cm = confusion_matrix(y_true=y_test, y_pred=y_pred, normalize='true')\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm,labels,preds): \n",
    "\n",
    "    # 绘制混淆矩阵\n",
    "    class_names = ['signal1','signal2']\n",
    "    title=\"confusion_matrix\"\n",
    "    ylabel='Ground Truth'\n",
    "    xlabel='Predicted Label'\n",
    "\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "\n",
    "    #plt.figure(figsize=(18, 12))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)  #plt.imshow(cm, interpolation='nearest',cmap='RdBu')\n",
    "    #plt.colorbar(label='tota1 test sample number')    \n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xticks(tick_marks,class_names,rotation=45)\n",
    "    plt.yticks(tick_marks,class_names)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.xlabel(xlabel)\n",
    "\n",
    "     # 保存图形\n",
    "    save_dir='数据报告'\n",
    "    if not os.path.isdir(save_dir):\n",
    "        os.mkdir(save_dir)\n",
    "\n",
    "    plt.savefig(save_dir+'DenseNet_Confusion_Matrix.png')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cm,labels,preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用sklearn的ConfusionMatrixDisplay画混淆矩阵\n",
    "# ConfusionMatrixDisplay 需要的参数: confusion_matrix(混淆矩阵), display_labels(标签名称列表)\n",
    "#disp.plot()函数内还可以加其他参数,'Accent', 'Accent_r', 'Blues', 'Blues_r', 'BrBG', 'BrBG_r', 'BuGn', 'BuGn_r', 'BuPu', 'BuPu_r', 'CMRmap', 'CMRmap_r', 'Dark2', 'Dark2_r', 'GnBu', 'GnBu_r', 'Greens', 'Greens_r', 'Greys', 'Greys_r', 'OrRd', 'OrRd_r', 'Oranges', 'Oranges_r', 'PRGn', 'PRGn_r', 'Paired', 'Paired_r', 'Pastel1', 'Pastel1_r', 'Pastel2',\n",
    "#'Pastel2_r', 'PiYG', 'PiYG_r', 'PuBu', 'PuBuGn', 'PuBuGn_r', 'PuBu_r', 'PuOr', 'PuOr_r', 'PuRd', 'PuRd_r', 'Purples', 'Purples_r', 'RdBu', 'RdBu_r', 'RdGy', 'RdGy_r', 'RdPu', 'RdPu_r', \n",
    "#'RdYlBu', 'RdYlBu_r', 'RdYlGn', 'RdYlGn_r', 'Reds', 'Reds_r', 'Set1', 'Set1_r', 'Set2', 'Set2_r', 'Set3', 'Set3_r', 'Spectral', 'Spectral_r', 'Wistia', 'Wistia_r', 'YlGn', 'YlGnBu', 'YlGnBu_r', \n",
    "#'YlGn_r', 'YlOrBr', 'YlOrBr_r', 'YlOrRd', 'YlOrRd_r', 'afmhot', 'afmhot_r', 'autumn', 'autumn_r', 'binary', 'binary_r', 'bone', 'bone_r', 'brg', 'brg_r', 'bwr', 'bwr_r', 'cividis', 'cividis_r', \n",
    "#'cool', 'cool_r', 'coolwarm', 'coolwarm_r', 'copper', 'copper_r', 'crest', 'crest_r', 'cubehelix','cubehelix_r', 'flag', 'flag_r', 'flare', 'flare_r', 'gist_earth', 'gist_earth_r', 'gist_gray', \n",
    "#'gist_gray_r', 'gist_heat', 'gist_heat_r', 'gist_ncar', 'gist_ncar_r', 'gist_rainbow', 'gist_rainbow_r','gist_stern', 'gist_stern_r', 'gist_yarg', 'gist_yarg_r', 'gnuplot', 'gnuplot2', 'gnuplot2_r', 'gnuplot_r', \n",
    "#'gray', 'gray_r', 'hot', 'hot_r', 'hsv', 'hsv_r', 'icefire', 'icefire_r', 'inferno', 'inferno_r', 'jet', 'jet_r', 'magma', 'magma_r', 'mako', 'mako_r', 'nipy_spectral', 'nipy_spectral_r', 'ocean', 'ocean_r', 'pink', 'pink_r', \n",
    "#'plasma', 'plasma_r', 'prism', 'prism_r', 'rainbow', 'rainbow_r', 'rocket', 'rocket_r', 'seismic', 'seismic_r', 'spring', 'spring_r', 'summer', 'summer_r', 'tab10', 'tab10_r', 'tab20', 'tab20_r', 'tab20b', 'tab20b_r', 'tab20c', 'tab20c_r', 'terrain',\n",
    "#'terrain_r', 'turbo', 'turbo_r', 'twilight', 'twilight_r', 'twilight_shifted', 'twilight_shifted_r', 'viridis', 'viridis_r','vlag', 'vlag_r', 'winter', 'winter_r'\n",
    "#如cmap，意思是colormap,有很多种类型。\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "cm = confusion_matrix(labels,preds)\n",
    "class_names = ['signal1','signal2']\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "#disp.plot() \n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 seaborn 对 confusion_matrix 进行可视化\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "class_names = ['signal1','signal2']\n",
    "title=\"confusion_matrix\"\n",
    "ylabel='Ground Truth'\n",
    "xlabel='Predicted Label'\n",
    "\n",
    "tick_marks = np.arange(len(class_names))\n",
    "\n",
    "cm=confusion_matrix(labels, preds)\n",
    "\n",
    "#sns.heatmap(cm, annot=True) \n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False) \n",
    "#sns.heatmap(cm, annot=True,cmap='PuOr') \n",
    "#sns.heatmap(cm, cmap=\"YlGnBu\",annot=True)\n",
    "\n",
    "plt.xlabel(xlabel,fontsize=20, color='k') #x轴label的文本和字体大小plt.xlabel(xlabel,fontsize=20, color='k')\n",
    "plt.ylabel(ylabel,fontsize=20, color='k') #y轴label的文本和字体大小plt.ylabel(ylabel,fontsize=20, color='k')\n",
    "plt.xticks(tick_marks,class_names,rotation=45) #plt.xticks(fontsize=20) #x轴刻度的字体大小\n",
    "plt.yticks(tick_marks,class_names)  #plt.yticks(fontsize=20) #y轴刻度的字体大小\n",
    "plt.title(title,fontsize=20) #图片标题文本和字体大小\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型性能综合评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算评价指标\n",
    "from sklearn.metrics import f1_score, mean_absolute_error, mean_squared_error, roc_auc_score \n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, ndcg_score\n",
    "\n",
    "# 定义计算F1-score的函数\n",
    "def calculate_f1_score(true_labels, predicted_labels):\n",
    "    return f1_score(true_labels, predicted_labels)\n",
    "\n",
    "# 定义计算MAE的函数\n",
    "def calculate_mae(true_values, predicted_values):\n",
    "    return mean_absolute_error(true_values, predicted_values)\n",
    "\n",
    "# 定义计算RMSE的函数\n",
    "def calculate_rmse(true_values, predicted_values):\n",
    "    return np.sqrt(mean_squared_error(true_values, predicted_values))\n",
    "\n",
    "\n",
    "# 定义计算Accuracy的函数\n",
    "def calculate_accuracy(true_labels, predicted_labels):\n",
    "    return accuracy_score(true_labels, predicted_labels)\n",
    "\n",
    "# 计算Precision@k指标\n",
    "def calculate_precision(true_labels, predicted_labels):    \n",
    "    return precision_score(true_labels, predicted_labels)\n",
    "\n",
    "# 定义计算Recall的函数\n",
    "def calculate_recall(true_labels, predicted_labels):\n",
    "    return recall_score(true_labels, predicted_labels)\n",
    "\n",
    "\n",
    "# 定义计算ROC AUC的函数\n",
    "def calculate_roc_auc(true_labels, predicted_scores):\n",
    "    return roc_auc_score(true_labels, predicted_scores)\n",
    "\n",
    "# 计算NDCG@k指标\n",
    "def compute_ndcg(predictions, targets, k):\n",
    "    ndcg_scores = ndcg_score(targets, predictions, k=k)\n",
    "    return ndcg_scores.mean()\n",
    "\n",
    "# 计算Hit Rate@k指标\n",
    "def compute_hit_rate(predictions, targets, k):\n",
    "    num_hits = 0\n",
    "    for i in range(len(predictions)):\n",
    "        if targets[i] in predictions[i, :k]:\n",
    "            num_hits += 1\n",
    "    return num_hits / len(predictions)\n",
    "\n",
    "# 计算Precision@k指标\n",
    "def compute_precision(predictions, targets, k):\n",
    "    precision_scores = []\n",
    "    for i in range(len(predictions)):\n",
    "        precision = precision_score([targets[i]], predictions[i, :k], average='micro')\n",
    "        precision_scores.append(precision)\n",
    "    return sum(precision_scores) / len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试评价计算\n",
    "print(\"F1-score:\", calculate_f1_score(labels, preds))\n",
    "print(\"Accuracy:\", calculate_accuracy(labels, preds))\n",
    "print(\"Precision:\", calculate_precision(labels, preds))\n",
    "print(\"Recall:\", calculate_recall(labels, preds))\n",
    "print(\"ROC_AUC:\", calculate_roc_auc(labels, preds))\n",
    "\n",
    "#print(f\"Precision@{k}: {precision:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 计算ROC曲线和AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROC（Receiver Operating Characteristic）曲线和AUC（Area Under the ROC Curve）是用于评估二分类模型性能的常用指标。\n",
    "# ROC展示了不同阈值下的真阳性率（True Positive Rate）与假阳性率（False Positive Rate）之间的关系。\n",
    "# AUC表示ROC曲线下的面积。AUC的值范围在0到1之间，数值越大表示模型性能越好。\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "\n",
    "# 计算ROC曲线和AUC\n",
    "fpr, tpr, thresholds = roc_curve(labels, preds)\n",
    "roc_auc = roc_auc_score(labels, preds) #roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# 可视化ROC曲线\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "# 保存图形\n",
    "save_dir='数据报告'\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.mkdir(save_dir)\n",
    "\n",
    "plt.savefig(save_dir+'DenseNet_AUC.png')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"AUC:\", roc_auc)\n",
    "\n",
    "#在这个示例中，我们首先生成随机的真实标签和预测概率。然后，使用roc_curve函数计算ROC曲线的真阳性率（True Positive Rate）\n",
    "#和假阳性率（False Positive Rate），以及阈值。\n",
    "#使用roc_auc_score或者auc函数计算AUC值。\n",
    "#最后，使用matplotlib库绘制ROC曲线图，并输出计算得到的AUC值。\n",
    "#您可以根据实际的模型预测结果和真实标签替换示例代码中的y_true和y_pred，以计算和可视化您的模型的ROC和AUC指标。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义测试模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test_model=Net()\n",
    "#Test_model.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试单张图片\n",
    "image_path = 'Data_Val/0.tif'  #替换为你的图片路径\n",
    "image = Image.open(image_path)\n",
    "plt.imshow(img)\n",
    "\n",
    "width, height = image.size\n",
    "channels = 1 if image.mode == 'L' else 3  # 灰度图像有1个通道，彩色图像有3个通道\n",
    "print(f\"Image dimensions: {width} x {height} x {channels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2、直接加载未处理的图片进行测试\n",
    "#单张测试图片并进行预处理\n",
    "def load_and_preprocess_image(image_path):\n",
    "    transform_valid = transforms.Compose([\n",
    "                    transforms.Resize((1024, 1024)),\n",
    "                    transforms.ToTensor()                    \n",
    "    ])\n",
    "\n",
    "    #image = glob.glob(image_path)\n",
    "    image = Image.open(image_path)   \n",
    "    image_tensor = transform_valid(image)\n",
    "    # 将单张图像添加到批次维度\n",
    "    image_tensor=torch.unsqueeze(image_tensor, 0)#或者image_tensor.unsqueeze(0)\n",
    "\n",
    "    return image_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = 'Data_Val/0.tif'  #替换为你的图片路径\n",
    "image = load_and_preprocess_image(image_path).to(device)\n",
    "\n",
    "output = model(image)\n",
    "\n",
    "#输出概率最大的类别\n",
    "_, predicted_class = torch.max(output, dim=1)\n",
    "predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage = F.softmax(output, dim=1)[0] * 100\n",
    "percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 得到预测结果，并且从大到小排序\n",
    "_, indices = torch.sort(output, descending=True)\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2、对预处理好的图片测试\n",
    "import random\n",
    "r_index = random.choice(range(len(test_ds)))\n",
    "\n",
    "x, y = test_ds[r_index]\n",
    "\n",
    "y = torch.tensor(y, dtype=torch.long)\n",
    "x, y = x.to(device), y.to(device)           \n",
    "\n",
    "y_pred = model(x)\n",
    "y_pred = torch.argmax(y_pred, dim=1)\n",
    "\n",
    "y,y_pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pt]",
   "language": "python",
   "name": "conda-env-pt-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
